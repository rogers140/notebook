{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "from time import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['GORDON_REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from matplotlib.path import Path\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing import Pool\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: an rgb image filen name, a kmeans object, M and L\n",
    "def getHistogram(fileName, patchSize=16, stride=56):\n",
    "    # Change image to gray scale\n",
    "    image = imread(fileName);\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY);\n",
    "    # Generate key points\n",
    "    height = img.shape[0];\n",
    "    width = img.shape[1];\n",
    "    xv, yv = np.meshgrid(np.arange(patchSize / 2, width - patchSize / 2, stride),\n",
    "                         np.arange(patchSize / 2, height - patchSize / 2, stride),\n",
    "                         indexing='ij');\n",
    "    sample_points = np.c_[xv.flat, yv.flat];\n",
    "    cv_keypoints = [cv2.KeyPoint(x,y, patchSize) for x, y in sample_points];\n",
    "    # Get SIFT descriptor.\n",
    "    sift = cv2.SIFT();\n",
    "    _, descriptors = sift.compute(img, cv_keypoints);\n",
    "    # Map key points with type.\n",
    "    cluster_labels = kmeans.predict(descriptors);\n",
    "    cluster_labels = cluster_labels;\n",
    "    # Level 0\n",
    "    weight_0 = 1.0 / (2**L);\n",
    "    histogram = np.bincount(cluster_labels, minlength = M);\n",
    "    histogram = histogram * weight_0;\n",
    "    # Other levels\n",
    "    for l in range(1, L + 1):\n",
    "        weight = 1.0 / (2**(L - l + 1));\n",
    "        grid_size_x = width / (2**l);\n",
    "        grid_size_y = height / (2**l);\n",
    "        grid_boundaries_x = range(0, width, grid_size_x);\n",
    "        grid_boundaries_y = range(0, height, grid_size_y);\n",
    "        number_of_grid = (2**l)**2;\n",
    "    \n",
    "        grid_crs = sample_points / [grid_size_x, grid_size_y];\n",
    "        grid_cols = grid_crs[:,0];  # x\n",
    "        grid_rows = grid_crs[:,1];  # y\n",
    "    \n",
    "        keypoint_grid_indices = grid_rows * (2**l) + grid_cols;\n",
    "        hists = np.zeros(shape=(number_of_grid, M), dtype=np.int);\n",
    "        for ki, label in zip(keypoint_grid_indices, cluster_labels):\n",
    "            hists[ki][label] += 1;\n",
    "        hists = hists * weight;\n",
    "        histogram = np.hstack((histogram, hists.flatten()));\n",
    "    return (histogram / len(sample_points)); # Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHistogramsForLabel(label):\n",
    "    dir_path = trainingDir + label + '/';\n",
    "    fileNames = os.listdir(dir_path);\n",
    "    # Choose 1000 samples for each class.\n",
    "    if len(fileNames) > 1000:\n",
    "        fileNames = random.sample(fileNames, 1000);\n",
    "    his_list = [];\n",
    "    for f in fileNames:\n",
    "        his_list.append(getHistogram(dir_path + f));\n",
    "    np.save('/oasis/projects/nsf/csd395/ruogu/svm3/histogram/' + label + '.npy', np.asarray(his_list));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = np.load('/oasis/projects/nsf/csd395/ruogu/svm3/vocabulary.npy');\n",
    "M = vocabulary.shape[0];\n",
    "L = 2;\n",
    "trainingDir = '/oasis/projects/nsf/csd395/yuncong/CSHL_data_patches/MD589_byLandmark/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='random', n_clusters=M, n_init=10);\n",
    "kmeans.fit(vocabulary);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating histogram for all patches takes 81.742166996 sec.\n"
     ]
    }
   ],
   "source": [
    "label_list = os.listdir(trainingDir);\n",
    "t = time();\n",
    "pool = Pool(processes=8);\n",
    "pool.map(getHistogramsForLabel, label_list);\n",
    "print \"Generating histogram for all patches takes {} sec.\".format(time() - t);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7n_surround', '7N', 'Gr', 'SuVe', 'Pn', 'LVe_surround', 'VLL_surround', 'VLL', 'LVe', '5N_surround', '12N', '7N_surround', '7n', 'Gr_surround', 'Pn_surround', 'SuVe_surround', '12N_surround', '5N']\n"
     ]
    }
   ],
   "source": [
    "print label_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
