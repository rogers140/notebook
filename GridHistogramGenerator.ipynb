{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "from time import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['GORDON_REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from matplotlib.path import Path\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = np.load('/oasis/projects/nsf/csd395/ruogu/vocabulary/m_400/vocabulary_stride_8.npy');\n",
    "M = vocabulary.shape[0];\n",
    "L = 2;\n",
    "trainingDir = '/oasis/projects/nsf/csd395/yuncong/CSHL_data_patches/MD589_byLandmark/';\n",
    "trainingHistogramDir = '/oasis/projects/nsf/csd395/ruogu/boosting/training_L2/';\n",
    "kmeans = KMeans(init='random', n_clusters=M, n_init=10);\n",
    "kmeans.fit(vocabulary);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input: an rgb image file name (full file path)\n",
    "def getHistogram(fileName, patchSize=16, stride=8):\n",
    "    # Change image to gray scale\n",
    "    image = imread(fileName);\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY);\n",
    "    # Generate key points\n",
    "    height = img.shape[0];\n",
    "    width = img.shape[1];\n",
    "    xv, yv = np.meshgrid(np.arange(patchSize / 2, width - patchSize / 2, stride),\n",
    "                         np.arange(patchSize / 2, height - patchSize / 2, stride),\n",
    "                         indexing='ij');\n",
    "    sample_points = np.c_[xv.flat, yv.flat];\n",
    "    cv_keypoints = [cv2.KeyPoint(x,y, patchSize) for x, y in sample_points];\n",
    "    # Get SIFT descriptor.\n",
    "    sift = cv2.SIFT();\n",
    "    _, descriptors = sift.compute(img, cv_keypoints);\n",
    "    # Map key points with label.\n",
    "    cluster_labels = kmeans.predict(descriptors);\n",
    "    # Level 0\n",
    "    weight_0 = 1.0 / (2**L);\n",
    "    histogram = np.bincount(cluster_labels, minlength = M);\n",
    "    histogram = histogram * weight_0;\n",
    "    # Other levels\n",
    "    for l in range(1, L + 1):\n",
    "        weight = 1.0 / (2**(L - l + 1));\n",
    "        grid_size_x = width / (2**l);\n",
    "        grid_size_y = height / (2**l);\n",
    "        grid_boundaries_x = range(0, width, grid_size_x);\n",
    "        grid_boundaries_y = range(0, height, grid_size_y);\n",
    "        number_of_grid = (2**l)**2;\n",
    "    \n",
    "        grid_crs = sample_points / [grid_size_x, grid_size_y];\n",
    "        grid_cols = grid_crs[:,0];  # col index\n",
    "        grid_rows = grid_crs[:,1];  # row index\n",
    "        keypoint_grid_indices = grid_rows * (2**l) + grid_cols;\n",
    "        hists = np.zeros(shape=(number_of_grid, M), dtype=np.int);\n",
    "        for ki, label in zip(keypoint_grid_indices, cluster_labels):\n",
    "            hists[ki][label] += 1;\n",
    "        hists = hists * weight;\n",
    "        histogram = np.hstack((histogram, hists.flatten()));\n",
    "    return (histogram / len(sample_points)); # Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating histograms for training data\n",
    "def getHistogramsForLabel(label):\n",
    "    dir_path = trainingDir + label + '/';\n",
    "    fileNames = os.listdir(dir_path);\n",
    "    # Choose 1000 samples for each class.\n",
    "    if len(fileNames) > 1000:\n",
    "        fileNames = random.sample(fileNames, 1000);\n",
    "    his_list = [];\n",
    "    filename_list = [];\n",
    "    for f in fileNames:\n",
    "        his_list.append(getHistogram(dir_path + f));\n",
    "        filename_list.append(dir_path + f);\n",
    "    np.save(trainingHistogramDir + label + '.npy', np.asarray(his_list));\n",
    "    pickle.dump(filename_list, open(trainingHistogramDir + label + '.p', \"wb\" ));\n",
    "    del his_list;\n",
    "    del filename_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating histogram for all patches takes 956.393076181 sec.\n"
     ]
    }
   ],
   "source": [
    "label_list = os.listdir(trainingDir);\n",
    "t = time();\n",
    "pool = Pool(processes=16);\n",
    "fileNames_label = pool.map(getHistogramsForLabel, label_list);\n",
    "pool.close();\n",
    "pool.join();\n",
    "print \"Generating histogram for all patches takes {} sec.\".format(time() - t);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating histogram for testing data\n",
    "# stack = 589;\n",
    "# section = 161\n",
    "# testingDir = '/oasis/projects/nsf/csd395/yuncong/CSHL_data_patches/MD'+str(stack)+'_byROI/'+str(section).zfill(4)+'/roi1/';\n",
    "# testingHistogramDir = '/oasis/projects/nsf/csd395/ruogu/svm7/histogram/testing/'+str(stack) + '/';\n",
    "\n",
    "# def getHistogramByName(fileName):\n",
    "#     his = getHistogram(testingDir + fileName);\n",
    "#     return (fileName, his);\n",
    "\n",
    "# testing_fileNames = os.listdir(testingDir);\n",
    "# t = time();\n",
    "# pool = Pool(processes=8);\n",
    "# testing_fileName_histograms = pool.map(getHistogramByName, testing_fileNames);\n",
    "# pool.close();\n",
    "# pool.join();\n",
    "# print \"Generating histogram for testing patches takes {} sec.\".format(time() - t);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing_histograms = np.asarray([x[1] for x in testing_fileName_histograms]);\n",
    "# testing_fileNames = [x[0] for x in testing_fileName_histograms];\n",
    "# np.save(testingHistogramDir + str(section).zfill(4) + '.npy', testing_histograms); # Save histogram files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # Save fileName list.\n",
    "# pickle.dump(testing_fileNames, open(testingHistogramDir + str(section).zfill(4) + '.p', 'wb'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
